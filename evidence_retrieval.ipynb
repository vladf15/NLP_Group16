{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbxp4cobYTm1"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iwT-czK2siB",
        "outputId": "9e232bcf-6cd9-43da-9ec7-959b4c674c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIbTMK5A3Jk6"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/drive/My Drive/val_claims_quantemp.json\") as f:\n",
        "  val_data = json.load(f)\n",
        "\n",
        "with open(\"/content/drive/My Drive/train_claims_quantemp.json\") as f:\n",
        "  train_data = json.load(f)\n",
        "\n",
        "with open(\"/content/drive/My Drive/test_claims_quantemp.json\") as f:\n",
        "  test_data = json.load(f)\n",
        "\n",
        "with open(\"/content/drive/My Drive/corpus_evidence_unified.json\") as f:\n",
        "  evidence_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lbYFCCAZKU6",
        "outputId": "48e417eb-faec-44aa-96b8-a0536d875312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.25.2)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "!pip install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# !pip install rank_bm25\n",
        "# from rank_bm25 import BM25Okapi\n",
        "# corpus = list(evidence_data.values())\n",
        "# tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "# bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "!pwd\n",
        "!cp /content/drive/MyDrive/fast_bm25.py /content/fast_bm25.py\n",
        "from fast_bm25 import BM25\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "def bm25_preprocess(text):\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize\n",
        "    tokens = text.split(' ')\n",
        "    return tokens\n",
        "\n",
        "corpus = list(evidence_data.values())\n",
        "tokenized_corpus = [bm25_preprocess(doc) for doc in corpus]\n",
        "bm25 = BM25(tokenized_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3-7oyse2mK6",
        "outputId": "b6b21ecb-740e-48b3-e0d6-2080f25b1f69",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/227.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sentence_transformers-3.0.1\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6SC5tMhGvPl",
        "outputId": "37be62f1-076d-4a19-cf46-0d8a201c76fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Initialize BERT tokenizer and model\n",
        "\n",
        "MODEL_NAME_RERANKER = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "bert_model = SentenceTransformer(MODEL_NAME_RERANKER)\n",
        "\n",
        "# Function to filter out similar documents based on cosine similarity\n",
        "def filter_similar_documents(docs, embeddings, threshold=0.75):\n",
        "    cos_sim_matrix = util.pytorch_cos_sim(embeddings, embeddings)\n",
        "    to_remove = set()\n",
        "    for i in range(len(docs)):\n",
        "        for j in range(i + 1, len(docs)):\n",
        "            if cos_sim_matrix[i, j] > threshold:\n",
        "                to_remove.add(j)\n",
        "    filtered_docs = [doc for i, doc in enumerate(docs) if i not in to_remove]\n",
        "    return filtered_docs\n",
        "\n",
        "# Function to re-rank and filter documents\n",
        "def retrieve_evidence(query, batch_size=16):\n",
        "    documents = bm25.get_top_n(bm25_preprocess(query), corpus, n=100)\n",
        "\n",
        "    # Encode query and documents\n",
        "    query_embedding = bert_model.encode(query, convert_to_tensor=True)\n",
        "    document_embeddings = bert_model.encode(documents, convert_to_tensor=True, batch_size=batch_size)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    query_embedding = query_embedding.to(device)\n",
        "    document_embeddings = document_embeddings.to(device)\n",
        "    # Calculate cosine similarity scores\n",
        "    scores = util.pytorch_cos_sim(query_embedding, document_embeddings).squeeze().tolist()\n",
        "\n",
        "    # Pair documents with their scores\n",
        "    reranked = list(zip(documents, scores))\n",
        "\n",
        "    # Sort documents by BERT score (higher is better)\n",
        "    reranked.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Extract the documents and their embeddings\n",
        "    sorted_docs = [doc for doc, score in reranked]\n",
        "    sorted_embeddings = torch.stack([embedding for embedding, (doc, score) in zip(document_embeddings, reranked)])\n",
        "\n",
        "\n",
        "    doc_to_score = {doc: score for (doc, score) in reranked}\n",
        "\n",
        "    # Filter similar documents\n",
        "    final_filtered_docs = filter_similar_documents(sorted_docs, sorted_embeddings, threshold=0.75)\n",
        "    return [(doc, doc_to_score[doc]) for doc in final_filtered_docs]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_evidences = {}"
      ],
      "metadata": {
        "id": "I8r0IiK-W0AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(0, len(val_data)):\n",
        "  claim = val_data[x]['claim']\n",
        "  doc_evidences[claim] = retrieve_evidence(claim)"
      ],
      "metadata": {
        "id": "4680RbuWWqe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "  \"label\": [d['label'].upper() for d in val_data],\n",
        "  \"claim\": [d['claim'] for d in val_data],\n",
        "  \"evidences\": [[e[0] for e in doc_evidences[d['claim']][:20]] for d in val_data],\n",
        "  \"scores\": [[e[1] for e in doc_evidences[d['claim']][:20]] for d in val_data]\n",
        "}"
      ],
      "metadata": {
        "id": "Yuua09uEVgeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df.to_csv('/content/drive/My Drive/val_top_20.csv', index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elbszkleaHoA",
        "outputId": "70dcaaaf-580b-4db6-848f-a60478c7bab4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            label                                              claim  \\\n",
            "0           FALSE  Amit Shah said Narendra Modi sleeps for 24 hou...   \n",
            "1           FALSE  Video of show Pakistani players celebrating th...   \n",
            "2            TRUE  Says Dino Rossi \"stripped\" health care \"from 4...   \n",
            "3           FALSE  Durch einen Vergleich mit den Symptomen einer ...   \n",
            "4           FALSE  A gun-toting Australian granny blew the testic...   \n",
            "...           ...                                                ...   \n",
            "3079        FALSE  Mark Zuckerberg is giving $1,000 away to Faceb...   \n",
            "3080        FALSE  Joe Biden said Democrats would cheat in 2022 b...   \n",
            "3081        FALSE  \"CNN to permanently close its doors as ratings...   \n",
            "3082  CONFLICTING  A recent study found \"that cities where Uber o...   \n",
            "3083         TRUE  The Biden administration \"published a study co...   \n",
            "\n",
            "                                              evidences  \\\n",
            "0     [prime minister narendra modi sleeps for only ...   \n",
            "1     [sep 10, 2023  summary: the much-anticipated m...   \n",
            "2     [dino john rossi (born october 15, 1959) is an...   \n",
            "3     [alternativ zu den bereits empfohlenen covid-1...   \n",
            "4     [two thugs raped her 18-year-old granddaughter...   \n",
            "...                                                 ...   \n",
            "3079  [1 dc. 2015  mark zuckerberg vows to donate 99...   \n",
            "3080  [2022-11-07  ... fraud once they know how many...   \n",
            "3081  [30 mar 2023  primetime ratings for cnn have f...   \n",
            "3082  [by a burton  2018  cited by 2  this paper inv...   \n",
            "3083  [petroleum and other liquid fuels will decline...   \n",
            "\n",
            "                                                 scores  \n",
            "0     [0.780240535736084, 0.7770113945007324, 0.4653...  \n",
            "1     [0.704868495464325, 0.547605037689209, 0.53384...  \n",
            "2     [0.4880216717720032, 0.4284822344779968, 0.423...  \n",
            "3     [0.6845248341560364, 0.6484535932540894, 0.559...  \n",
            "4     [0.6279321908950806, 0.48085129261016846, 0.41...  \n",
            "...                                                 ...  \n",
            "3079  [0.749610185623169, 0.7417542934417725, 0.7316...  \n",
            "3080  [0.632871150970459, 0.6296520233154297, 0.6287...  \n",
            "3081  [0.6092782020568848, 0.5551339387893677, 0.533...  \n",
            "3082  [0.7510182857513428, 0.7250652313232422, 0.612...  \n",
            "3083  [0.6525353789329529, 0.5943098664283752, 0.574...  \n",
            "\n",
            "[3084 rows x 4 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}