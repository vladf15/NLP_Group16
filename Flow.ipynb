{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b15b92a8-775f-4087-b0cc-dbd474ac3f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "import transformers\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from rank_bm25 import BM25Okapi\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer, BartTokenizer, BartForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27229930-0db7-4b01-851a-3d31d624a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9efad823-21ea-4055-8efe-cd8a1cb70f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your datasets\n",
    "train_path = 'NumTemp-E9C0/data/raw_data/train_claims_quantemp.json'\n",
    "val_path = 'NumTemp-E9C0/data/raw_data/val_claims_quantemp.json'\n",
    "test_path = 'NumTemp-E9C0/data/raw_data/test_claims_quantemp.json'\n",
    "evidence_path = 'NumTemp-E9C0/data/corpus_evidence_unified.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f671e218-454c-4324-b23a-fa479add58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_claims_and_labels(file_path):\n",
    "    \"\"\"\n",
    "    Extracts claims and labels from the given JSON file and converts them into a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the claims and labels.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Extract only the \"label\" and \"claim\" fields\n",
    "    extracted_data = [{'label': item['label'], 'claim': item['claim']} for item in data]\n",
    "\n",
    "    # Convert the extracted data to a DataFrame\n",
    "    df_claims = pd.DataFrame(extracted_data)\n",
    "\n",
    "    return df_claims\n",
    "\n",
    "# Convert the extracted data to a DataFrame\n",
    "df_claim_train = extract_claims_and_labels(train_path)\n",
    "df_claim_val = extract_claims_and_labels(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b746979-dbf3-4eff-b15f-a9b7fc74a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract evidence snippits from the corpus\n",
    "with open(evidence_path, 'r', encoding='utf-8') as file:\n",
    "    evidence_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9aade9d4-c9e4-4683-85c6-057a02847eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 Evidence Collector\n",
    "# Initialize BERT tokenizer and model\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "bert_model = BertForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "# Move model to the GPU\n",
    "bert_model.to(device)\n",
    "\n",
    "corpus = list(evidence_data.values())\n",
    "\n",
    "# Tokenize the entire corpus once\n",
    "def tokenize_corpus(corpus):\n",
    "    return [doc.split(\" \") for doc in corpus]\n",
    "\n",
    "# Function to retrieve top-k documents using BM25 and re-rank using BERT\n",
    "def retrieve_evidence(query, bm25, corpus, k=5):\n",
    "    # BM25 retrieval\n",
    "    tokenized_query = query.split(\" \")\n",
    "    bm25_top_k = bm25.get_top_n(tokenized_query, corpus, n=250)  # Adjust 'n' as needed\n",
    "    \n",
    "    # Tokenize the query once for BERT\n",
    "    tokenized_query_bert = bert_tokenizer.encode_plus(query, add_special_tokens=True, return_tensors='pt', truncation=True, max_length=512)\n",
    "    tokenized_query_bert = {key: value.to(device) for key, value in tokenized_query_bert.items()}\n",
    "    \n",
    "    # Tokenize the BM25 top-k documents for BERT\n",
    "    tokenized_corpus_bert = [bert_tokenizer.encode_plus(doc, add_special_tokens=True, return_tensors='pt', truncation=True, max_length=512) for doc in bm25_top_k]\n",
    "    \n",
    "    # Process documents in batches\n",
    "    batch_size = 64\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(0, len(tokenized_corpus_bert), batch_size):\n",
    "        batch = tokenized_corpus_bert[i:i+batch_size]\n",
    "        batch = [{key: value.to(device) for key, value in doc.items()} for doc in batch]  # Move each document to GPU\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = [bert_model(**{**tokenized_query_bert, **doc}) for doc in batch]  # Perform inference on GPU\n",
    "            batch_scores = [output.logits.squeeze().item() for output in outputs]\n",
    "        \n",
    "        scores.extend(batch_scores)\n",
    "    \n",
    "    # Re-rank documents based on scores\n",
    "    ranked_documents = sorted(zip(bm25_top_k, scores), key=lambda x: x[1], reverse=True)\n",
    "    top_k_evidences = [doc for doc, score in ranked_documents[:k]]\n",
    "    \n",
    "    return top_k_evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32d4f014-08bc-449c-a019-a263329b7898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 9935/9935 [16:14:29<00:00,  5.89s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 3084/3084 [4:12:07<00:00,  4.91s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def add_top_k_evidences(df, bm25, corpus, k=5):\n",
    "    df['top_k_evidences'] = df['claim'].progress_apply(lambda claim: retrieve_evidence(claim, bm25, corpus, k))\n",
    "    return df\n",
    "\n",
    "# Assuming df_claim_train and df_claim_val are your DataFrames containing the claims and labels\n",
    "# Tokenize the corpus once for BM25\n",
    "tokenized_corpus = tokenize_corpus(corpus)\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "df_claim_train = add_top_k_evidences(df_claim_train, bm25, corpus, k=5)\n",
    "df_claim_val = add_top_k_evidences(df_claim_val, bm25, corpus, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fce218-6f2c-467a-a7e9-85932f9b2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the DataFrames from CSV files\n",
    "#df_claim_train.to_csv('df_claim_train.csv', index=False)\n",
    "#df_claim_val.to_csv('df_claim_val.csv', index=False)\n",
    "\n",
    "# Load the DataFrames from CSV files\n",
    "df_claim_train = pd.read_csv('df_claim_train.csv')\n",
    "df_claim_val = pd.read_csv('df_claim_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c401f33b-d82d-4e9b-85e0-fbec11bb8b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claim_train['label'] = df_claim_train['label'].replace({'False':0, 'Conflicting':1, 'True':2})\n",
    "df_claim_val['label'] = df_claim_val['label'].replace({'False':0, 'Conflicting':1, 'True':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f18ed-0605-4096-a6f2-0819435ccfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587ce21a7c6a43038a61c4a0168b386d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9935 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba735c3809a344b58f668b7ad102c69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3084 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformers.logging.set_verbosity_error()\n",
    "final_dataset_train = Dataset.from_pandas(df_claim_train)\n",
    "final_dataset_val = Dataset.from_pandas(df_claim_val)\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "model = BartForSequenceClassification.from_pretrained('facebook/bart-large-mnli', num_labels=3)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['top_k_evidences'], examples['claim'], truncation=True, padding='max_length', max_length=1024)\n",
    "\n",
    "encoded_dataset_train = final_dataset_train.map(preprocess_function, batched=True)\n",
    "encoded_dataset_val = final_dataset_val.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bb8ccf-2006-4b35-839b-fe1e222ce678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "transformers.logging.set_verbosity(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2648adfd-89ce-4757-8af3-14de34dba818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_steps = 5000,\n",
    "    # Specify to use CUDA\n",
    "    use_cpu=False,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset_train,\n",
    "    eval_dataset=encoded_dataset_val\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b81fffd-791e-4702-9067-881310ea382a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
